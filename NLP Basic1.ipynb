{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846dd628",
   "metadata": {},
   "source": [
    "# Natural Language Processing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e895f7a",
   "metadata": {},
   "source": [
    "# Introduction for Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be37c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube Link:https://www.youtube.com/watch?v=xvqsFTUsOmc&t=203s\n",
    "# Related Link:https://www.pyohio.org/2018/schedule/presentation/38/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python language is not a natural language. So Python was written for coding whereas natural language\n",
    "# are languages that have naturally evolved over time that humans actually use to communicate and then\n",
    "# processing is a processor on a computer. So it's how the computer carries out instructions and so\n",
    "# natural language processing is how a computer is able to process the natural languages. So natural\n",
    "# language processing is just simply how to deal with text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cef03a",
   "metadata": {},
   "source": [
    "# How to deal with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3010dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP falls under the greater branch of Artificial Intelligence. AI is all about computer performing\n",
    "# tasks that a human can do so that includes things like image processing, people can see then how to\n",
    "# make a computer can see. In this case since we're dealing with language humans can interpret language\n",
    "# so how can we make the machine interpret language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444efaaf",
   "metadata": {},
   "source": [
    "# Examples of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c630ec7",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9578106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example1: you are a manager for selling hats and shirts. You got thousands of call to make reviews \n",
    "# for your hats and shirts.You can do is you can use NLP techniques to actually read the text and \n",
    "# out is this is a positive emotion or this is a negative emotion. So this idea is called sentiment\n",
    "# analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594374bd",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example2: you're working at a legal firm and you're working on a case where someone at a comapny may\n",
    "# embezzled some money and so you're looking for 10,000 email to find some emails are related to \n",
    "# embezzle money. What you can do is you can look at all your emails and then you can label them not\n",
    "# you manually labelling them but you can have a machine using NLP technique to label them.\n",
    "# So this idea here is a very powerful NLP technique called topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349ce48",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example3: you're working for an inspirational quote company and you have been tasked to write \n",
    "# inspirational quotes for 365 days of the year and you've written it for 11 months but you're just\n",
    "# completely out of ideas and you're thinking about coding something up that will write inspirational\n",
    "# quotes for me based on past codes. This idea called text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c611746",
   "metadata": {},
   "source": [
    "# Data Science Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eac37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start with a Question\n",
    "# 2. Get & Clean the Data\n",
    "# 3. Perform EDA:exploratory data analysis\n",
    "# 4. Apply Techniques\n",
    "# 5. Share Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4806f33",
   "metadata": {},
   "source": [
    "# A Simple Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Question: \"If I study more, will I get a higher grade?\"\n",
    "# 2. Data: Student/Hours Studied/Grade--clean the data, set two as 2 and 998 as 98\n",
    "# 3. Perform EDA: I want to quickly understand and quickly see if my data makes sense. So this is \n",
    "# typially done through visualization techniques. I'd create a scatter plot so just by looking at\n",
    "# this scatter plot:\n",
    "# Finding #1: The more you study, the higher grade you will get.\n",
    "# Finding #2: Also, Charlie is a smarty pants.\n",
    "# 4. Apply Techniques: the most basic technique is a linear regression. So fitting a line to our model.\n",
    "# Grade = 1.5*hours + 65\n",
    "# 5. Share Insights: Yes, there us a positive correlation between the number of hours you study and\n",
    "# the grade you will get. Specifically, the relationship is: Grade = 1.5*Hours + 65. So if you study 10 \n",
    "# hours, you can expect to get an 80. Howeverm Charlie is a smarty pants and is inflating the grade \n",
    "# estimate. You'll probably get slightly less than 80."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd78181",
   "metadata": {},
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972faac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Exploratory Data Analysis\n",
    "# NLP Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856a719",
   "metadata": {},
   "source": [
    "# Question:What makes Ali Wong's comedy routine stand out?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e24f6",
   "metadata": {},
   "source": [
    "# Data Gathering + Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34442e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Input: the question we have in our head, \"how Ali Wong different?\"\n",
    "# 2. Output: clean, organized data in standard format that looks like..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce71b2",
   "metadata": {},
   "source": [
    "#  Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611592d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Where are we going to get this data?\n",
    "# I just googled Ali Wong Baby Cobra transcript and then it came up.\n",
    "# 2. How much data should we get? Which comedians? What time range?\n",
    "# I said I wanted to compare Ali Wong with other comedians so how would you decide how many comedians\n",
    "# to compare with her. The way I did this is I went to IMDB because IMDB has advanced search option \n",
    "# and I tried to adjust the filters so that I would get 10 comedians including Ali Wong and I ended up \n",
    "# kind of tweaking the features: tweaking the filters to make this make sense.\n",
    "# This is where you're going to need to DEFINE THE SCOPE of your project based on your DOMAIN EXPERTISE.\n",
    "# 3. Here's HOW I decided to limit my scope:\n",
    "    # a. Stand up comedy specials from the last 5 years. \n",
    "    # b. At least a 7.5 rating with 2000+ votes on IMDB.\n",
    "    # C. If a comedian has multiple specials, I keep the one with the highest rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d093151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB SCRAPING: Requests, Beautiful Soup\n",
    "# SAVING PYTHON DATA: Pickle\n",
    "# Requests: 1. Formal--Make HTTP requests; 2. Simple--Get info from a website\n",
    "# Beautiful Soup: 1. Formal-- Parse HTML documents; 2. Simple--Extract parts of website\n",
    "# Pickle: 1. Formal--Serialize Python Objects; 2. Simple--Save data for later\n",
    "\n",
    "# Requests, Beautiful Soup, Pickle are all Python Packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212ebbe",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638cdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format #1: Corpus = a collection of texts\n",
    "    # a. Pandas: Python library for data analysis\n",
    "    # b. DataFrame: A pandas object, essentially a table\n",
    "# Format #2: Document-Term Matrix\n",
    "    # a. Clean Text-remove excess, unnessary parts of the text\n",
    "    # b. Tokenize Text-split the text into smaller pieces\n",
    "    # c. Document-Term Matrix-put into a matrix so a machine can read it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1b695",
   "metadata": {},
   "source": [
    "# Example for Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90c0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a line here, what would do to make this data cleaner? The line as below:\n",
    "# All right, Petunia. Wish me luck out there. You will die on August 7th, 2037.\n",
    "# How would a computer read this? It needs to be cleaned, tokenized and put into a matrix.\n",
    "# Common data cleaning steps:\n",
    "    # 1. Remove punctuations\n",
    "    # 2. Remove numbers\n",
    "    # 3. Lowercase letters\n",
    "# After done all the steps above, we will get: all right petunia wish me luck out there you will die \n",
    "# on august\n",
    "# The way do that is regular expression in Python\n",
    "# Regular Expression is a Python library, basically a way to search for patterns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60191bd",
   "metadata": {},
   "source": [
    "# Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3512f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization means split text into smaller pieces aka a token. The most common token size is a WORD.\n",
    "# It can also be a SENTENCE.\n",
    "# So in this case, we tokenize this sentence up here by word. Every word is its own item.\n",
    "# Now that every word is its own token, you can filter out words that have very little meaning-these\n",
    "# are called STOP WORDS.\n",
    "# So we remove the STOP WORDS in English like \"all, on....\"\n",
    "# At the end of the day, we end up with just these words: \"right petunia wish luck die august\"\n",
    "# This presentation of the text is called A BAG OF WORDS MODEL. It's a simple format that ignores order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771166b",
   "metadata": {},
   "source": [
    "# Put into a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cec8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason we need to put the data in a matrix is because we need to store this info for multiple\n",
    "# documents.\n",
    "# Document-Term Matrix:\n",
    "    # 1. Each row is a different document (or a different transcript, in our case)\n",
    "    # 2. Each column is a different term (usually words, but can also be bi-grams like 'thank you')\n",
    "    # 3. The values are word counts\n",
    "    \n",
    "# We do this within Scikit-learn (this is Python machine learning library). There is this function\n",
    "# called count vectorizer which helps us create this document-term matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421a7b9",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Input: the question, \"how is Ali Wong different?\"\n",
    "# 2. Data Gathering: scope project and scrape data from website\n",
    "# 3. Data Cleaning: put data into standard formats for future analysis\n",
    "# 4. Ouput: a corpus and a document-term matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
